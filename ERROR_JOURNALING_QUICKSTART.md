# ğŸ‰ Error Journaling System - Quick Start

## âœ… System Ready!

All error journaling infrastructure is now installed and tested.

## ğŸš€ Try It Now

### Method 1: VS Code Tasks (Easiest)

1. Press `Ctrl+Shift+P` (or `Cmd+Shift+P` on Mac)
2. Type "Tasks: Run Task"
3. Select **"Run: Vitest (logged)"**
4. Watch the test run with automatic error logging!

### Method 2: Command Line

```powershell
# Windows
pwsh -File scripts/log_wrap.ps1 --tag vitest --cmd "pwsh -File scripts/run_vitest.ps1 debounce" --art "exercises/js/coverage/coverage-final.json"

# Linux/Mac
bash scripts/log_wrap.sh --tag vitest --cmd "bash scripts/run_vitest.sh debounce" --art "exercises/js/coverage/coverage-final.json"
```

## ğŸ“Š View Results

After a few test runs:

```powershell
python tools/aggregate_errors.py
```

You'll see:
- Total runs and success rate
- Top recurring failures
- Quest generation suggestions

## ğŸ® Current Status

âœ… **Test Run**: 1 successful Vitest run logged
âœ… **Journal**: `logs/error-journal.ndjson` created
âœ… **Success Rate**: 100% (no failures yet)

## ğŸ“ What Was Created

```
.vscode/
  â””â”€ tasks.json                    # âœ… 5 logging tasks ready

scripts/
  â”œâ”€ log_wrap.ps1                  # âœ… Windows wrapper
  â””â”€ log_wrap.sh                   # âœ… Linux/Mac wrapper

tools/
  â””â”€ aggregate_errors.py           # âœ… Analysis tool

logs/
  â””â”€ error-journal.ndjson          # âœ… 1 entry captured

docs/
  â””â”€ ERROR_JOURNALING.md           # âœ… Full documentation
```

## ğŸ¯ Next Steps

### 1. Run More Tests (5 min)
```powershell
# Try all the logging tasks:
# - Run: Vitest (logged)
# - Run: Pytest (logged)  
# - Run: Judge Agent Test (logged)
```

### 2. Analyze Patterns (2 min)
```powershell
python tools/aggregate_errors.py
```

### 3. Create Your First Error-Based Quest (15 min)
- Look at top recurring errors
- Copy `seed/quests/js_debounce_B.json` as a template
- Modify to reproduce the error
- Add to skill tree

## ğŸ’¡ Pro Tips

### Track Quest Performance
```powershell
$env:QUEST_ID = "quest-js-debounce-b"
# Run task...
# Now errors are linked to this quest!
```

### View Journal Entries
```powershell
Get-Content logs/error-journal.ndjson | ConvertFrom-Json | Select-Object ts, tag, exit_code | Format-Table
```

### Sample a Failing Test
```powershell
# Create a broken test
$badCode = @"
export function debounce() {
  return undefined; // This will fail!
}
"@
Set-Content exercises/js/src/debounce-broken.ts -Value $badCode

# Run and capture the failure
pwsh -File scripts/log_wrap.ps1 --tag vitest-fail --cmd "npm test"

# Analyze
python tools/aggregate_errors.py
```

## ğŸ“š Documentation

- **ERROR_JOURNALING.md** - Complete documentation
- **TESTING_DEPLOYMENT.md** - Testing and deployment guide
- **SETUP_COMPLETE.md** - System overview

## ğŸ”¥ Cool Features

âœ¨ **Automatic fingerprinting** - Dedupe repeated errors
âœ¨ **Coverage capture** - See coverage when tests fail
âœ¨ **Quest linking** - Track errors per quest
âœ¨ **Cross-platform** - Works everywhere
âœ¨ **VS Code integration** - One-click testing
âœ¨ **Historical analysis** - Track progress over time

## ğŸ“ Example: Build a Quest from Real Errors

1. **Collect errors** (work for a few days)
2. **Run analysis**:
   ```
   python tools/aggregate_errors.py
   
   Top failure:
   [vitest] Ã— 15 occurrences
   Error: Cannot read property 'length' of undefined
   ```

3. **Create quest**: `seed/quests/js_nullcheck_B.json`
   ```json
   {
     "id": "quest-js-nullcheck-b",
     "concept": "js.defensive",
     "symptom": "Cannot read property 'length' of undefined",
     "goal": "Add null checks before accessing properties"
   }
   ```

4. **Students fix real errors you encountered!**

## ğŸš€ You're All Set!

The error journaling system is **fully operational** and ready to:
- Capture every test run
- Track failures and successes
- Generate quest ideas from real errors
- Provide data-driven insights

**Start running tests and watch your error database grow!** ğŸ“ˆ
