name: CI Smoke Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  guardrail-tests:
    name: Guardrail Tests - Model Configuration
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run guardrail test for model defaults
        run: |
          python tests/test_env_model.py
      
      - name: Verify model version in code
        run: |
          # Ensure code defaults to gemini-2.5-flash
          grep -q "gemini-2\.5-flash" arcade_app/agent.py || \
            (echo "ERROR: Model default not set to gemini-2.5-flash" && exit 1)
          echo "✓ Model default verified in code"

  cloud-run-smoke-tests:
    name: Cloud Run Smoke Tests
    runs-on: ubuntu-latest
    needs: guardrail-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Get Cloud Run service URL
        id: get-url
        run: |
          BASE=$(gcloud run services describe evalforge-agents \
            --region us-central1 \
            --format='value(status.url)')
          echo "BASE_URL=$BASE" >> $GITHUB_OUTPUT
      
      - name: Verify environment variables in Cloud Run
        run: |
          # Check that gemini-2.5-flash is configured
          gcloud run services describe evalforge-agents \
            --region us-central1 \
            --format="value(spec.template.spec.containers[0].env)" | \
            grep -q "gemini-2\.5-flash" || \
            (echo "ERROR: Model version not set to gemini-2.5-flash in Cloud Run" && exit 1)
          echo "✓ Cloud Run environment variable verified"
      
      - name: Test list-apps endpoint
        env:
          BASE_URL: ${{ steps.get-url.outputs.BASE_URL }}
        run: |
          curl -sf "$BASE_URL/list-apps?relative_path=arcade_app" > /dev/null || \
            (echo "ERROR: list-apps endpoint failed" && exit 1)
          echo "✓ list-apps endpoint passed"
      
      - name: Test session creation
        env:
          BASE_URL: ${{ steps.get-url.outputs.BASE_URL }}
        run: |
          curl -sf -X POST -H "Content-Length: 0" \
            "$BASE_URL/apps/arcade_app/users/user/sessions" > /dev/null || \
            (echo "ERROR: session creation failed" && exit 1)
          echo "✓ session creation passed"
      
      - name: Verify model version in deployment
        run: |
          gcloud run services describe evalforge-agents \
            --region us-central1 \
            --format="value(spec.template.spec.containers[0].env)" | \
            grep "gemini-2\.5-flash" || \
            (echo "ERROR: Model version verification failed" && exit 1)
          echo "✓ Model version verification passed"
      
      - name: Check for Vertex AI errors in logs
        run: |
          # Check recent logs for 404/403 errors
          ERRORS=$(gcloud logging read \
            'resource.type="cloud_run_revision" 
             AND resource.labels.service_name="evalforge-agents" 
             AND (textPayload:"404 NOT_FOUND" OR textPayload:"403 PERMISSION_DENIED")
             AND timestamp>="'$(date -u -d '5 minutes ago' --iso-8601=seconds)'"' \
            --limit=10 \
            --format='value(textPayload)' 2>/dev/null || echo "")
          
          if [ ! -z "$ERRORS" ]; then
            echo "WARNING: Found Vertex AI errors in logs:"
            echo "$ERRORS"
            exit 1
          fi
          echo "✓ No Vertex AI errors in recent logs"

  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [guardrail-tests, cloud-run-smoke-tests]
    if: always()
    
    steps:
      - name: Check test results
        run: |
          echo "Guardrail Tests: ${{ needs.guardrail-tests.result }}"
          echo "Cloud Run Tests: ${{ needs.cloud-run-smoke-tests.result }}"
          
          if [ "${{ needs.guardrail-tests.result }}" != "success" ]; then
            echo "❌ Guardrail tests failed"
            exit 1
          fi
          
          if [ "${{ needs.cloud-run-smoke-tests.result }}" == "failure" ]; then
            echo "❌ Cloud Run smoke tests failed"
            exit 1
          fi
          
          echo "✅ All tests passed"
